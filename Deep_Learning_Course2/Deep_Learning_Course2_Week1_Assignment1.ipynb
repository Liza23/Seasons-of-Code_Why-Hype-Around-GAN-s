{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning.Course2.Week1.Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOy4FcjAzfTOU3MB9ccDyhr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liza23/Seasons-of-Code_Why-Hype-Around-GAN-s/blob/master/Deep_Learning_Course2_Week1_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTxGlz8YeIUa",
        "colab_type": "text"
      },
      "source": [
        "Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LEJzm_oeMFx",
        "colab_type": "text"
      },
      "source": [
        "Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "531IQ3aqdRuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "from init_utils import sigmoid, relu, compute_loss, forward_propagation, backward_propagation\n",
        "from init_utils import update_parameters, predict, load_dataset, plot_decision_boundary, predict_dec\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# load image dataset: blue/red dots in circles\n",
        "train_X, train_Y, test_X, test_Y = load_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA1xlXAeeSM8",
        "colab_type": "text"
      },
      "source": [
        "Neural Network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uAe7JSxeVEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X, Y, learning_rate = 0.01, num_iterations = 15000, print_cost = True, initialization = \"he\"):\n",
        "    \"\"\"\n",
        "    Implements a three-layer neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SIGMOID.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (2, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples)\n",
        "    learning_rate -- learning rate for gradient descent \n",
        "    num_iterations -- number of iterations to run gradient descent\n",
        "    print_cost -- if True, print the cost every 1000 iterations\n",
        "    initialization -- flag to choose which initialization to use (\"zeros\",\"random\" or \"he\")\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model\n",
        "    \"\"\"\n",
        "        \n",
        "    grads = {}\n",
        "    costs = [] # to keep track of the loss\n",
        "    m = X.shape[1] # number of examples\n",
        "    layers_dims = [X.shape[0], 10, 5, 1]\n",
        "    \n",
        "    # Initialize parameters dictionary.\n",
        "    if initialization == \"zeros\":\n",
        "        parameters = initialize_parameters_zeros(layers_dims)\n",
        "    elif initialization == \"random\":\n",
        "        parameters = initialize_parameters_random(layers_dims)\n",
        "    elif initialization == \"he\":\n",
        "        parameters = initialize_parameters_he(layers_dims)\n",
        "\n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID.\n",
        "        a3, cache = forward_propagation(X, parameters)\n",
        "        \n",
        "        # Loss\n",
        "        cost = compute_loss(a3, Y)\n",
        "\n",
        "        # Backward propagation.\n",
        "        grads = backward_propagation(X, Y, cache)\n",
        "        \n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        \n",
        "        # Print the loss every 1000 iterations\n",
        "        if print_cost and i % 1000 == 0:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the loss\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2IQaWKfS61",
        "colab_type": "text"
      },
      "source": [
        "Zero Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7M-S7DAfVYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: initialize_parameters_zeros \n",
        "\n",
        "def initialize_parameters_zeros(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # number of layers in the network\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        ### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
        "        parameters['W' + str(l)] = np.zeros((layers_dims[l],layers_dims[l-1]))\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
        "        ### END CODE HERE ###\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nIc5DqhfYPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = initialize_parameters_zeros([3,2,1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw3PhebVfgUf",
        "colab_type": "text"
      },
      "source": [
        "* Testing code now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh1hPuEcfiTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"zeros\")\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ADPsszfj2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"predictions_train = \" + str(predictions_train))\n",
        "print (\"predictions_test = \" + str(predictions_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqfKoHD5foGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Model with Zeros initialization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-1.5,1.5])\n",
        "axes.set_ylim([-1.5,1.5])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDaRbvZOfv6K",
        "colab_type": "text"
      },
      "source": [
        "Random Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1IA2Ae3fxlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: initialize_parameters_random\n",
        "\n",
        "def initialize_parameters_random(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(3)               # This seed makes sure your \"random\" numbers will be the as ours\n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # integer representing the number of layers\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        ### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1])*10        \n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Do4vR9IhebZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = initialize_parameters_random([3, 2, 1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUiP5QZIhiiZ",
        "colab_type": "text"
      },
      "source": [
        "* Testing code now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yXIDtQ5hkNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"random\")\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2zEtaTNhvMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (predictions_train)\n",
        "print (predictions_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzJ4XDWthxbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Model with large random initialization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-1.5,1.5])\n",
        "axes.set_ylim([-1.5,1.5])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yrpTZyYh1kh",
        "colab_type": "text"
      },
      "source": [
        "He Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Ui9w2Ih3zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: initialize_parameters_he\n",
        "\n",
        "def initialize_parameters_he(layers_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the size of each layer.\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])\n",
        "                    b1 -- bias vector of shape (layers_dims[1], 1)\n",
        "                    ...\n",
        "                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])\n",
        "                    bL -- bias vector of shape (layers_dims[L], 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layers_dims) - 1 # integer representing the number of layers\n",
        "     \n",
        "    for l in range(1, L + 1):\n",
        "        ### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1])*np.sqrt(2./layers_dims[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FT0b1iMixMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = initialize_parameters_he([2, 4, 1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptiH3LO4i0aW",
        "colab_type": "text"
      },
      "source": [
        "* Testing code now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z821r1Vi2Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = model(train_X, train_Y, initialization = \"he\")\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(train_X, train_Y, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(test_X, test_Y, parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv2SzaOFi4tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Model with He initialization\")\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-1.5,1.5])\n",
        "axes.set_ylim([-1.5,1.5])\n",
        "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}